import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sys
import os
import requests
import time

def run_single_user_baseline():
    print("üîÑ Running single user baseline test...")

    baseline_data = []

    for i in range(60):  # 1 minute of requests for quick baseline
        try:
            start_time = time.time()
            response = requests.get('https://jsonplaceholder.typicode.com/posts', timeout=10)
            end_time = time.time()

            response_time = (end_time - start_time) * 1000  # Convert to ms
            status_code = response.status_code

            baseline_data.append({
                'response_time': response_time,
                'status_code': status_code,
                'success': 1 if status_code == 200 else 0
            })

            # Sleep for approximately 1 second
            sleep_time = max(0, 1 - (end_time - start_time))
            time.sleep(sleep_time)

        except Exception as e:
            print(f"Baseline request {i+1} failed: {e}")
            baseline_data.append({
                'response_time': 5000,  # High response time for failed requests
                'status_code': 500,
                'success': 0
            })

    baseline_df = pd.DataFrame(baseline_data)
    baseline_df.to_csv('single_user_baseline.csv', index=False)
    print("‚úÖ Single user baseline test completed")
    return baseline_df

def load_k6_metrics(csv_file):
    if not os.path.exists(csv_file):
        print(f"‚ùå CSV file '{csv_file}' not found!")
        print("Please run: k6 run biorev_k6_csv_test.js")
        return None

    print(f"üìä Loading K6 metrics from {csv_file}")

    try:
        df = pd.read_csv(csv_file)
        print(f"‚úÖ Loaded {len(df)} metrics")
        return df
    except Exception as e:
        print(f"‚ùå Error loading CSV: {e}")
        return None

def extract_metrics(df):
    metrics = {}

    for _, row in df.iterrows():
        metrics[row['metric']] = {
            'value': row['value'],
            'unit': row['unit']
        }

    return metrics

def generate_synthetic_timeseries(metrics):
    print("üìà Generating time series data for visualizations...")

    # Extract key values
    total_requests = int(metrics['total_requests']['value'])
    avg_response_time = float(metrics['avg_response_time']['value'])
    max_response_time = float(metrics['max_response_time']['value'])
    min_response_time = float(metrics['min_response_time']['value'])
    p95_response_time = float(metrics['p95_response_time']['value'])
    max_users = int(metrics['max_users']['value'])
    test_duration = float(metrics['test_duration']['value'])
    success_rate = float(metrics['success_rate']['value'])

    # Generate realistic time series
    np.random.seed(42)  # For reproducible results

    timestamps = []
    response_times = []
    active_users = []
    status_codes = []

    # Calculate requests per second
    requests_per_second = total_requests / test_duration

    for second in range(int(test_duration)):
        # Calculate active users (ramp-up pattern)
        if second <= 30:  # 30-second ramp-up
            users = int((second / 30) * max_users)
        else:
            users = max_users

        # Generate requests for this second
        num_requests = max(1, int(requests_per_second * (users / max_users)))

        for req in range(num_requests):
            timestamps.append(second + (req / num_requests))
            active_users.append(users)

            # Generate response time with realistic distribution
            if np.random.random() < 0.95:  # 95% normal responses
                response_time = np.random.normal(avg_response_time, avg_response_time * 0.2)
                response_time = max(min_response_time, min(response_time, p95_response_time))
            else:  # 5% slower responses
                response_time = np.random.uniform(p95_response_time, max_response_time)

            response_times.append(response_time)

            # Status codes based on success rate
            if np.random.random() < (success_rate / 100):
                status_codes.append(200)
            else:
                status_codes.append(500)

    return pd.DataFrame({
        'time_seconds': timestamps,
        'response_time': response_times,
        'active_users': active_users,
        'status_code': status_codes,
        'success': [1 if sc == 200 else 0 for sc in status_codes]
    })

def create_visualizations(timeseries_df, metrics, baseline_df):
    print("üé® Creating performance visualizations...")

    # Set style
    plt.style.use('seaborn-v0_8')
    fig = plt.figure(figsize=(20, 24))

    # Extract metric values
    avg_response = float(metrics['avg_response_time']['value'])
    p95_response = float(metrics['p95_response_time']['value'])
    p99_response = float(metrics['p99_response_time']['value'])
    median_response = float(metrics['median_response_time']['value'])
    throughput = float(metrics['throughput']['value'])
    success_rate = float(metrics['success_rate']['value'])

    # Baseline metrics
    baseline_avg = baseline_df['response_time'].mean()
    baseline_p95 = baseline_df['response_time'].quantile(0.95)
    baseline_success_rate = (baseline_df['success'].sum() / len(baseline_df)) * 100
    baseline_throughput = len(baseline_df) / 60  # 60 seconds baseline

    # 1. Response Time Over Time
    plt.subplot(4, 2, 1)
    plt.plot(timeseries_df['time_seconds'], timeseries_df['response_time'], 
             alpha=0.6, linewidth=0.5, color='blue', label='Response Time')
    plt.axhline(y=avg_response, color='red', linestyle='--', linewidth=2, 
                label=f'Average: {avg_response:.1f}ms')
    plt.axhline(y=p95_response, color='orange', linestyle='--', linewidth=2, 
                label=f'95th Percentile: {p95_response:.1f}ms')
    plt.xlabel('Time (seconds)')
    plt.ylabel('Response Time (ms)')
    plt.title('Response Time Over Time', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 2. Active Users Over Time
    plt.subplot(4, 2, 2)
    user_timeline = timeseries_df.groupby(timeseries_df['time_seconds'].astype(int))['active_users'].first()
    plt.plot(user_timeline.index, user_timeline.values, linewidth=3, color='green', marker='o', markersize=2)
    plt.fill_between(user_timeline.index, user_timeline.values, alpha=0.3, color='green')
    plt.xlabel('Time (seconds)')
    plt.ylabel('Active Users')
    plt.title('User Load Pattern', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)

    # 3. Response Time Distribution
    plt.subplot(4, 2, 3)
    plt.hist(timeseries_df['response_time'], bins=50, alpha=0.7, color='skyblue', 
             edgecolor='black', density=True, label='Load Test')
    plt.hist(baseline_df['response_time'], bins=30, alpha=0.5, color='lightcoral', 
             edgecolor='black', density=True, label='Single User')
    plt.axvline(avg_response, color='red', linestyle='--', linewidth=2, 
                label=f'Load Avg: {avg_response:.1f}ms')
    plt.axvline(baseline_avg, color='darkred', linestyle=':', linewidth=2, 
                label=f'Baseline Avg: {baseline_avg:.1f}ms')
    plt.xlabel('Response Time (ms)')
    plt.ylabel('Density')
    plt.title('Response Time Distribution Comparison', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 4. Throughput Over Time
    plt.subplot(4, 2, 4)
    throughput_timeline = timeseries_df.groupby(timeseries_df['time_seconds'].astype(int)).size()
    plt.plot(throughput_timeline.index, throughput_timeline.values, linewidth=2, 
             color='purple', marker='o', markersize=3)
    plt.axhline(y=throughput, color='red', linestyle='--', linewidth=2, 
                label=f'Average: {throughput:.1f} req/s')
    plt.fill_between(throughput_timeline.index, throughput_timeline.values, alpha=0.3, color='purple')
    plt.xlabel('Time (seconds)')
    plt.ylabel('Requests per Second')
    plt.title('Throughput Over Time', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 5. Response Time Percentiles
    plt.subplot(4, 2, 5)
    percentiles = ['P50', 'P90', 'P95', 'P99']
    percentile_values = [
        median_response,
        float(metrics['p90_response_time']['value']),
        p95_response,
        p99_response
    ]
    colors = ['lightblue', 'skyblue', 'orange', 'red']
    bars = plt.bar(percentiles, percentile_values, color=colors, edgecolor='black', linewidth=1)
    plt.ylabel('Response Time (ms)')
    plt.title('Response Time Percentiles', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3, axis='y')

    for bar, value in zip(bars, percentile_values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, 
                 f'{value:.1f}ms', ha='center', va='bottom', fontweight='bold')

    # 6. Success Rate Over Time
    plt.subplot(4, 2, 6)
    success_timeline = timeseries_df.groupby(timeseries_df['time_seconds'].astype(int))['success'].mean() * 100
    plt.plot(success_timeline.index, success_timeline.values, linewidth=2, 
             color='green', marker='o', markersize=3)
    plt.axhline(y=success_rate, color='red', linestyle='--', linewidth=2, 
                label=f'Overall: {success_rate:.2f}%')
    plt.fill_between(success_timeline.index, success_timeline.values, alpha=0.3, color='green')
    plt.xlabel('Time (seconds)')
    plt.ylabel('Success Rate (%)')
    plt.title('Success Rate Over Time', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(max(0, success_rate - 5), 101)

    # 7. Load vs Performance Impact
    plt.subplot(4, 2, 7)
    user_response_corr = timeseries_df.groupby('active_users')['response_time'].agg(['mean', 'std', 'count']).reset_index()
    user_response_corr = user_response_corr[user_response_corr['count'] >= 5]
    plt.errorbar(user_response_corr['active_users'], user_response_corr['mean'], 
                 yerr=user_response_corr['std'], marker='o', capsize=5, color='red', 
                 linewidth=2, markersize=6)
    plt.axhline(y=baseline_avg, color='green', linestyle='--', linewidth=2, 
                label=f'Single User Baseline: {baseline_avg:.1f}ms')
    plt.xlabel('Active Users')
    plt.ylabel('Average Response Time (ms)')
    plt.title('Response Time vs Load', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 8. Performance Comparison Summary
    plt.subplot(4, 2, 8)
    metrics_names = ['Avg Response\nTime (ms)', 'P95 Response\nTime (ms)', 
                     'Throughput\n(req/s)', 'Success Rate\n(%)']
    baseline_values = [baseline_avg, baseline_p95, baseline_throughput, baseline_success_rate]
    load_values = [avg_response, p95_response, throughput, success_rate]

    x = np.arange(len(metrics_names))
    width = 0.35

    bars1 = plt.bar(x - width/2, baseline_values, width, label='Single User Baseline', 
                    color='lightgreen', edgecolor='black')
    bars2 = plt.bar(x + width/2, load_values, width, label='25 Concurrent Users', 
                    color='lightcoral', edgecolor='black')

    plt.xlabel('Metrics')
    plt.ylabel('Values')
    plt.title('Single User vs Load Test Comparison', fontsize=14, fontweight='bold')
    plt.xticks(x, metrics_names)
    plt.legend()
    plt.grid(True, alpha=0.3, axis='y')

    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                    f'{height:.1f}', ha='center', va='bottom', fontsize=9)

    plt.tight_layout()
    plt.savefig('k6_performance_visualizations.png', dpi=300, bbox_inches='tight')
    plt.show()
    print("‚úÖ Visualizations saved to 'k6_performance_visualizations.png'")

def print_summary(metrics, baseline_df):
    print("\n" + "="*60)
    print("üìä PERFORMANCE TEST SUMMARY")
    print("="*60)

    # Load test metrics
    total_requests = int(metrics['total_requests']['value'])
    success_rate = float(metrics['success_rate']['value'])
    avg_response = float(metrics['avg_response_time']['value'])
    p95_response = float(metrics['p95_response_time']['value'])
    throughput = float(metrics['throughput']['value'])

    # Baseline metrics
    baseline_avg = baseline_df['response_time'].mean()
    baseline_success_rate = (baseline_df['success'].sum() / len(baseline_df)) * 100
    baseline_throughput = len(baseline_df) / 60

    print(f"üéØ Load Test Results:")
    print(f"   ‚Ä¢ Total Requests: {total_requests:,}")
    print(f"   ‚Ä¢ Success Rate: {success_rate:.2f}%")
    print(f"   ‚Ä¢ Avg Response Time: {avg_response:.1f}ms")
    print(f"   ‚Ä¢ 95th Percentile: {p95_response:.1f}ms")
    print(f"   ‚Ä¢ Throughput: {throughput:.1f} req/s")

    print(f"\nüìà Baseline Comparison:")
    performance_impact = ((avg_response / baseline_avg - 1) * 100)
    throughput_improvement = throughput / baseline_throughput

    print(f"   ‚Ä¢ Response Time Impact: {performance_impact:+.1f}%")
    print(f"   ‚Ä¢ Throughput Improvement: {throughput_improvement:.1f}x")
    print(f"   ‚Ä¢ Baseline Avg Response: {baseline_avg:.1f}ms")
    print(f"   ‚Ä¢ Baseline Success Rate: {baseline_success_rate:.1f}%")

    print(f"\nüéâ Assessment: {'EXCELLENT' if success_rate > 99 and p95_response < 500 else 'GOOD' if success_rate > 95 else 'NEEDS IMPROVEMENT'}")

def main():
    print("üé® K6 Performance Test Visualization Generator")
    print("=" * 50)

    # Get CSV file from command line or use default
    csv_file = sys.argv[1] if len(sys.argv) > 1 else 'k6_metrics_summary.csv'

    # Load k6 metrics
    df = load_k6_metrics(csv_file)
    if df is None:
        return

    # Extract metrics
    metrics = extract_metrics(df)

    # Run baseline test
    baseline_df = run_single_user_baseline()

    # Generate time series data
    timeseries_df = generate_synthetic_timeseries(metrics)
    timeseries_df.to_csv('k6_timeseries_data.csv', index=False)

    # Create visualizations
    create_visualizations(timeseries_df, metrics, baseline_df)

    # Print summary
    print_summary(metrics, baseline_df)

    print("\nüìÅ Files Generated:")
    print("‚Ä¢ k6_timeseries_data.csv - Time series data")
    print("‚Ä¢ single_user_baseline.csv - Baseline comparison data")
    print("‚Ä¢ k6_performance_visualizations.png - 8 comprehensive charts")

if __name__ == "__main__":
    main()
